---
# YAML metadata
title: Data science is a culture not a science
author: Matthew Brett
bibliography: ../data-science-bib/data_science.bib
---

# First slide

\centerline{\includegraphics[width=5in]{images/sexiest_job.png}}

Harvard Business Review

# Definitions

> Data Science is about drawing useful conclusions from large and diverse data
> sets through exploration, prediction, and inference.

Ani Adhikari, John DeNero et al (2018) "Computational and Inferential
Thinking" https://www.inferentialthinking.com

# Definitions

"Data scientists mostly do arithmetic and that's a good thing"

https://m.signalvnoise.com/data-scientists-mostly-just-do-arithmetic-and-that-s-a-good-thing-c6371885f7f6

Recommended reading for "What the *&!% is data science?" from Hadley Wickham's
"STATS 337: Readings in Applied Data Science"
https://github.com/hadley/stats337

# Data science in history

\centerline{\includegraphics[width=4in]{images/chambers_phone_calls.png}}

John Chambers (1998) "Computing with data: Concepts and challenges":
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.419.1750

# Code at the heart

> ... in modern computing, there should not be a sharp distinction between
> users and programmers. Most programming with statistical systems is done by
> users, and should be. As soon as the system doesn’t do quite what the user
> wants, the choice is to give up or to become a programmer, by modifying what
> the system currently does.

John Chambers (1998) "Computing with data: Concepts and challenges":
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.419.1750

# Code at the heart

"Think it, describe it, do it"

"Programming languages are languages"

Hadley Wickham (2018) “You can't do data science in a GUI”
https://www.youtube.com/watch?v=cpbtcsGE0OA

# Code at the heart

> Computers are an indispensable partner.

Leo Breiman (2001) "Statistical modeling: The two cultures", Statistical
Science (16) 199-231

# Data analysis culture

> Far better an approximate answer to the right question, which is often
> vague, than an exact answer to the wrong question, which can always be made
> precise.

John Tukey (1962) "The future of data analysis" The annals of mathematical
statistics (33) 1-67.

# Tools and attitudes: tools

> If we are to make progress in data analysis .. we need to pay attention to
> our tools and our attitudes. If these are adequate, our goals will take care
> of themselves.
>
> We dare not neglect any of the tools that have proved useful in the past.
> But equally we dare not find ourselves confined to their use. If algebra and
> analysis cannot help us, we must press on just the same, making as good use
> of intuition and originality as we know how.

John Tukey (1962) "The future of data analysis" The annals of mathematical
statistics (33) 1-67.

# Tools and attitudes: attitudes

> Almost all the most vital attitudes can be described in a type form:
> willingness to face up to *X*.

where *X* includes:

* more realistic problems,
* the necessarily approximate nature of useful results in data analysis,
* the need for collecting the results of actual experience with specific
  data-analytic techniques,
* the need for iterative procedures,
* free use of ad hoc and informal procedures, and
* the fact that data analysis is intrinsically an empirical science.

John Tukey (1962) "The future of data analysis" The annals of mathematical
statistics (33) 1-67.

# Definitions

> ... an academic data scientist is a scientist, trained in anything from
> social science to biology, who works with large amounts of data, and must
> grapple with computational problems posed by the structure, size, messiness,
> and the complexity and nature of the data, while simultaneously solving a
> real-world problem.

Cathy O'Neil, Rachel Schutt (2014) "Doing Data Science" O'Reilly.

# Tukey consulting

* Fire Control Research Office
* The Kinsey Report (Cochran, Mosteller and Tukey, 1953, 1954);
* Panel on Seismic Improvement (Tukey, 1959);
* Environmental pollution (Tukey et al., 1965; Tukey, 1966);
* The National Halothane Study (Subcommittee on the National Halothane Study,
  1966d; Gentleman, Gilbert and Tukey, 1969);
* National Assessment of Educational Progress (Tukey, 1970);
* Impacts of Stratospheric Change (Tukey, 1976);
* Adjustment of the U.S. Census (Ericksen, Kadane and Tukey, 1989; Tukey,
  1990).

* Munitions
* Halothane
* Census
* Atmospheric pollutants

# Leo Breiman consulting

> ... trying to figure out what freeway traffic looked like and what its
> statistical characteristics were.

> A lot of the problems that we dealt with in those days involved large
> amounts of data. For instance, in one big project we had seven years of
> hourly and daily data on over 450 variables relevant to air pollution. We
> were trying to predict next day ozone levels in the Los Angeles Basin.

> a study of delay in criminal courts in Colorado.

Richard Olsen (2001) "A Conversation with Leo Breiman" Statistical Science
(16) 184–198

# John Chambers consulting

\centerline{\includegraphics[width=4in]{images/chambers_phone_calls.png}}

John Chambers (1998) "Computing with data: Concepts and challenges":
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.419.1750

# Oh dear

> With enough data, the numbers speak for themselves. ... Petabytes allow us
> to say: "Correlation is enough." ... Correlation supersedes causation.

Chris Anderson (2008). The end of theory: The data deluge makes the scientific
method obsolete. Wired Magazine. Updated 6/23/2008), Available at: http://www.
wired. com/science/discoveries/magazine/16-07/pb_theory.

# The chief

I have good news and bad news.

# Is this the end?

Yes, it's the end of the talk.

All material for this talk at:
https://github.com/matthew-brett/data-science-discussions/berkeley-talk
